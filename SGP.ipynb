{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra, Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "invalid redefinition of constant Main.SGP",
     "output_type": "error",
     "traceback": [
      "invalid redefinition of constant Main.SGP\n",
      "\n",
      "Stacktrace:\n",
      " [1] top-level scope\n",
      "   @ c:\\Users\\mridu\\Desktop\\Julia\\SGP.ipynb:3"
     ]
    }
   ],
   "source": [
    "abstract type AbstractSurrogateModel end\n",
    "\n",
    "mutable struct SGP <: AbstractSurrogateModel\n",
    "    name::String\n",
    "    options::Dict{String, Any}\n",
    "    Z::Array{Float64, 2}\n",
    "    woodbury_data::Dict{String, Any}\n",
    "    optimal_par::Dict{String, Any}\n",
    "    optimal_noise::Float64\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_predict_variances (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function SGP(; kwargs...)\n",
    "    options = Dict(\n",
    "        \"corr\" => \"squar_exp\",\n",
    "        \"poly\" => \"constant\",\n",
    "        \"theta_bounds\" => [1e-6, 1e2],\n",
    "        \"noise0\" => [1e-2],\n",
    "        \"hyper_opt\" => \"Cobyla\",\n",
    "        \"eval_noise\" => true,\n",
    "        \"nugget\" => 1000.0 * eps(Float64),\n",
    "        \"method\" => \"FITC\",\n",
    "        \"n_inducing\" => 10\n",
    "    )\n",
    "\n",
    "    for (key, value) in kwargs\n",
    "        options[key] = value\n",
    "    end\n",
    "\n",
    "    Z = get(options, \"Z\", rand(3, 2))  # Providing a default value for Z if not provided\n",
    "    woodbury_data = get(options, \"woodbury_data\", Dict(\"vec\" => rand(3), \"inv\" => rand(3, 3)))  # Providing default values for woodbury_data\n",
    "    optimal_par = get(options, \"optimal_par\", Dict(\"theta\" => rand(2), \"sigma2\" => rand()))  # Providing default values for optimal_par\n",
    "    optimal_noise = get(options, \"optimal_noise\", rand())  # Providing a default value for optimal_noise\n",
    "\n",
    "    SGP(\"SGP\", options, Z, woodbury_data, optimal_par, optimal_noise)\n",
    "end\n",
    "\n",
    "\n",
    "function set_inducing_inputs!(sgp::SGP, Z::Matrix{Float64}, normalize::Bool=false)\n",
    "    if size(Z, 1) != size(sgp.X, 1)\n",
    "        error(\"Number of rows of Z must be equal to the number of rows of the input matrix\")\n",
    "    end\n",
    "\n",
    "    if normalize\n",
    "        # Implement normalization if needed\n",
    "    end\n",
    "\n",
    "    sgp.Z = copy(Z)\n",
    "end\n",
    "\n",
    "\n",
    "function _compute_K(sgp::SGP, A::Matrix{Float64}, B::Matrix{Float64}, theta::Vector{Float64}, sigma2::Float64)\n",
    "    dx = A .- B  # Compute element-wise differences\n",
    "    d = _componentwise_distance(sgp, dx)\n",
    "    r = _correlation_types(sgp, sgp.options[\"corr\"], theta, d)\n",
    "    R = reshape(r, (size(A, 1), size(B, 1)))\n",
    "    K = sigma2 * R\n",
    "    return K\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "function _fitc(sgp::SGP, X::Array{Float64, 2}, Y::Array{Float64, 2}, Z::Array{Float64, 2}, theta::Array{Float64, 1}, sigma2::Float64, noise::Float64, nugget::Float64)\n",
    "    Knn = fill(sigma2, size(X, 1))\n",
    "    Kmm = _compute_K(sgp, Z, Z, theta, sigma2) + I * nugget\n",
    "    Kmn = _compute_K(sgp, Z, X, theta, sigma2)\n",
    "\n",
    "    U = cholesky(Kmm).L\n",
    "    Ui = inv(U)\n",
    "    V = Ui * Kmn\n",
    "\n",
    "    eta2 = noise\n",
    "\n",
    "    nu = Knn - sum(V.^2, dims=1)' + eta2\n",
    "    beta = 1.0 ./ nu\n",
    "\n",
    "    A = I + V * (beta .* V')\n",
    "    L = cholesky(A).L\n",
    "    Li = inv(L)\n",
    "\n",
    "    a = Y .* beta'\n",
    "    b = Li * V * a\n",
    "\n",
    "    likelihood = -0.5 * (sum(log.(nu)) + 2.0 * sum(log.(diag(L))) + a' * Y - dot(b, b))\n",
    "\n",
    "    LiUi = Li * Ui\n",
    "    LiUiT = LiUi'\n",
    "    woodbury_vec = LiUiT * b\n",
    "    woodbury_inv = Ui' * Ui - LiUiT * LiUi\n",
    "\n",
    "    return likelihood, woodbury_vec, woodbury_inv\n",
    "end\n",
    "\n",
    "function _vfe(sgp::SGP, X::Array{Float64, 2}, Y::Array{Float64, 2}, Z::Array{Float64, 2}, theta::Array{Float64, 1}, sigma2::Float64, noise::Float64, nugget::Float64)\n",
    "    mean = 0\n",
    "    Y .-= mean\n",
    "\n",
    "    Kmm = _compute_K(sgp, Z, Z, theta, sigma2) + I * nugget\n",
    "    Kmn = _compute_K(sgp, Z, X, theta, sigma2)\n",
    "\n",
    "    U = cholesky(Kmm).L\n",
    "    Ui = inv(U)\n",
    "    V = Ui * Kmn\n",
    "\n",
    "    beta = 1.0 ./ max.(noise, nugget)\n",
    "\n",
    "    A = beta .* V * V'\n",
    "    B = I + A\n",
    "    L = cholesky(B).L\n",
    "    Li = inv(L)\n",
    "\n",
    "    b = beta * Li * V * Y\n",
    "\n",
    "    likelihood = -0.5 * (-size(Y, 1) * log(beta) + 2.0 * sum(log.(diag(L))) + beta * dot(Y, Y) - dot(b, b) + size(Y, 1) * beta * sigma2 - sum(diag(A)))\n",
    "\n",
    "    LiUi = Li * Ui\n",
    "    Bi = I + Li' * Li\n",
    "    woodbury_vec = LiUi' * b\n",
    "    woodbury_inv = Ui' * Bi * Ui\n",
    "\n",
    "    return likelihood, woodbury_vec, woodbury_inv\n",
    "end\n",
    "\n",
    "function _predict_values(sgp::SGP, x::Array{Float64, 2})\n",
    "    n_features_x = size(x, 2)\n",
    "    n_features_Z = size(sgp.Z, 2)\n",
    "    if n_features_x != n_features_Z\n",
    "        error(\"Number of features in x must be equal to the number of features in sgp.Z\")\n",
    "    end\n",
    "\n",
    "    theta = sgp.optimal_par[\"theta\"]\n",
    "    if length(theta) != n_features_x\n",
    "        error(\"Length of the theta vector must match the number of features in x and sgp.Z\")\n",
    "    end\n",
    "\n",
    "    Kx = _compute_K(sgp, x, sgp.Z, theta, sgp.optimal_par[\"sigma2\"])\n",
    "    mu = Kx * sgp.woodbury_data[\"vec\"]\n",
    "    return mu\n",
    "end\n",
    "\n",
    "\n",
    "function _predict_variances(sgp::SGP, x::Array{Float64, 2})\n",
    "    Kx = _compute_K(sgp, sgp.Z, x, sgp.optimal_par[\"theta\"], sgp.optimal_par[\"sigma2\"])\n",
    "    Kxx = fill(sgp.optimal_par[\"sigma2\"], size(x, 1))\n",
    "    var = (Kxx - sum((sgp.woodbury_data[\"inv\"]' * Kx) .* Kx, dims=1))' .+ sgp.optimal_noise\n",
    "    var = max.(var, 1e-15)\n",
    "    return var\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3122906925667791"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assign sample values for SGP\n",
    "X_sgp = rand(10, 2)\n",
    "Y_sgp = rand(10)\n",
    "Z_sgp = rand(3, 2)\n",
    "Î¸_sgp = rand(2)\n",
    "sigma2_sgp = rand()\n",
    "noise_sgp = rand()\n",
    "nugget_sgp = rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGP(\"SGP\", Dict{String, Any}(\"hyper_opt\" => \"Cobyla\", \"method\" => \"FITC\", \"eval_noise\" => true, \"poly\" => \"constant\", \"corr\" => \"squar_exp\", \"nugget\" => 2.220446049250313e-13, \"noise0\" => [0.01], \"n_inducing\" => 10, \"theta_bounds\" => [1.0e-6, 100.0]), [0.49939767431290083 0.08719320140650544; 0.00762973725878191 0.02605838810346406; 0.17293385677642048 0.1572087261263786], Dict{String, Any}(\"vec\" => [0.4955302398047676, 0.5647264285719458, 0.6754476078296348], \"inv\" => [0.14925874908913805 0.4062406545453081 0.5102084418937607; 0.57330552680985 0.787300049471846 0.03115872433620004; 0.240734223963317 0.3788392074574267 0.1340756822828979]), Dict{String, Any}(\"theta\" => [0.20077895109436905, 0.640775114094781], \"sigma2\" => 0.9540648751646907), 0.018604213213631482)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create an instance of SGP\n",
    "sgp_instance = SGP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "setfield!: immutable struct of type SGP cannot be changed",
     "output_type": "error",
     "traceback": [
      "setfield!: immutable struct of type SGP cannot be changed\n",
      "\n",
      "Stacktrace:\n",
      " [1] setproperty!(x::SGP, f::Symbol, v::Matrix{Float64})\n",
      "   @ Base .\\Base.jl:41\n",
      " [2] top-level scope\n",
      "   @ c:\\Users\\mridu\\Desktop\\Julia\\SGP.ipynb:8"
     ]
    }
   ],
   "source": [
    "# Assuming X_sgp has dimensions (10, 2)\n",
    "num_rows_Xsgp = size(X_sgp, 1)\n",
    "\n",
    "# Repeat sgp_instance.Z vertically to match X_sgp\n",
    "repeated_Z = vcat(sgp_instance.Z, repeat(sgp_instance.Z, num_rows_Xsgp - 1))\n",
    "\n",
    "# Set the modified Z in sgp_instance\n",
    "sgp_instance.Z = repeated_Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "DimensionMismatch",
     "evalue": "DimensionMismatch: arrays could not be broadcast to a common size; got a dimension with lengths 10 and 3",
     "output_type": "error",
     "traceback": [
      "DimensionMismatch: arrays could not be broadcast to a common size; got a dimension with lengths 10 and 3\n",
      "\n",
      "Stacktrace:\n",
      "  [1] _bcs1\n",
      "    @ .\\broadcast.jl:555 [inlined]\n",
      "  [2] _bcs\n",
      "    @ .\\broadcast.jl:549 [inlined]\n",
      "  [3] broadcast_shape\n",
      "    @ .\\broadcast.jl:543 [inlined]\n",
      "  [4] combine_axes\n",
      "    @ .\\broadcast.jl:524 [inlined]\n",
      "  [5] instantiate\n",
      "    @ .\\broadcast.jl:306 [inlined]\n",
      "  [6] materialize\n",
      "    @ .\\broadcast.jl:903 [inlined]\n",
      "  [7] _compute_K(sgp::SGP, A::Matrix{Float64}, B::Matrix{Float64}, theta::Vector{Float64}, sigma2::Float64)\n",
      "    @ Main c:\\Users\\mridu\\Desktop\\Julia\\SGP.ipynb:41\n",
      "  [8] _predict_values(sgp::SGP, x::Matrix{Float64})\n",
      "    @ Main c:\\Users\\mridu\\Desktop\\Julia\\SGP.ipynb:124\n",
      "  [9] var\"##core#272\"()\n",
      "    @ Main C:\\Users\\mridu\\.julia\\packages\\BenchmarkTools\\QNsku\\src\\execution.jl:561\n",
      " [10] var\"##sample#273\"(::Tuple{}, __params::BenchmarkTools.Parameters)\n",
      "    @ Main C:\\Users\\mridu\\.julia\\packages\\BenchmarkTools\\QNsku\\src\\execution.jl:570\n",
      " [11] _lineartrial(b::BenchmarkTools.Benchmark, p::BenchmarkTools.Parameters; maxevals::Int64, kwargs::@Kwargs{})\n",
      "    @ BenchmarkTools C:\\Users\\mridu\\.julia\\packages\\BenchmarkTools\\QNsku\\src\\execution.jl:187\n",
      " [12] _lineartrial(b::BenchmarkTools.Benchmark, p::BenchmarkTools.Parameters)\n",
      "    @ BenchmarkTools C:\\Users\\mridu\\.julia\\packages\\BenchmarkTools\\QNsku\\src\\execution.jl:182\n",
      " [13] #invokelatest#2\n",
      "    @ .\\essentials.jl:887 [inlined]\n",
      " [14] invokelatest\n",
      "    @ .\\essentials.jl:884 [inlined]\n",
      " [15] #lineartrial#46\n",
      "    @ C:\\Users\\mridu\\.julia\\packages\\BenchmarkTools\\QNsku\\src\\execution.jl:51 [inlined]\n",
      " [16] lineartrial\n",
      "    @ C:\\Users\\mridu\\.julia\\packages\\BenchmarkTools\\QNsku\\src\\execution.jl:50 [inlined]\n",
      " [17] tune!(b::BenchmarkTools.Benchmark, p::BenchmarkTools.Parameters; progressid::Nothing, nleaves::Float64, ndone::Float64, verbose::Bool, pad::String, kwargs::@Kwargs{})\n",
      "    @ BenchmarkTools C:\\Users\\mridu\\.julia\\packages\\BenchmarkTools\\QNsku\\src\\execution.jl:300\n",
      " [18] tune!\n",
      "    @ BenchmarkTools C:\\Users\\mridu\\.julia\\packages\\BenchmarkTools\\QNsku\\src\\execution.jl:289 [inlined]\n",
      " [19] tune!(b::BenchmarkTools.Benchmark)\n",
      "    @ BenchmarkTools C:\\Users\\mridu\\.julia\\packages\\BenchmarkTools\\QNsku\\src\\execution.jl:289\n",
      " [20] top-level scope\n",
      "    @ C:\\Users\\mridu\\.julia\\packages\\BenchmarkTools\\QNsku\\src\\execution.jl:666"
     ]
    }
   ],
   "source": [
    "@btime _predict_values(sgp_instance, X_sgp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.0",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
